{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e981ed",
   "metadata": {},
   "source": [
    "### NOTE: Neither lines of code nor text have been proofread and the Face-Recognition module does not work with Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d188c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "import face_recognition   # Does not work with Windows, so Jupiter Notebook should be run in Linux\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import requests\n",
    "import imutils\n",
    "\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f75968",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /io/opencv/modules/imgcodecs/src/loadsave.cpp:802: error: (-215:Assertion failed) !buf.empty() in function 'imdecode_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m frame_req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m      7\u001b[0m frame_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mbytearray\u001b[39m(frame_req\u001b[38;5;241m.\u001b[39mcontent), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m----> 8\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m frame \u001b[38;5;241m=\u001b[39m imutils\u001b[38;5;241m.\u001b[39mresize(frame, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)\n\u001b[1;32m     10\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAndroid_cam\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /io/opencv/modules/imgcodecs/src/loadsave.cpp:802: error: (-215:Assertion failed) !buf.empty() in function 'imdecode_'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Captures from a mobile phone camera but does not save the frames\"\"\"\n",
    "\n",
    "url = \"http://xxxxx/shot.jpg\"\n",
    "\n",
    "while True: \n",
    "    frame_req = requests.get(url)\n",
    "    frame_arr = np.array(bytearray(frame_req.content), dtype=np.uint8)\n",
    "    frame = cv.imdecode(frame_arr, -1)\n",
    "    frame = imutils.resize(frame, width=640, height=400)\n",
    "    cv.imshow(\"Android_cam\", frame)\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):  # The user should open capture window\n",
    "        break                      # striking the 'q' key ends the capture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519161bc",
   "metadata": {},
   "source": [
    "The above is not very good for face recognition; see\n",
    "<br>\n",
    "https://www.linkedin.com/advice/1/how-can-you-ensure-facial-recognition-accuracy-jr7de?utm_source=share&utm_medium=member_android&utm_campaign=share_via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60950f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b1794",
   "metadata": {},
   "source": [
    "Face recognition from IP webcam (mobile phone camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ef9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://xxxxx/shot.jpg\"\n",
    "\n",
    "\n",
    "# Defining the path for encodings from training image files\n",
    "DEFAULT_ENCODINGS_PATH = Path(\"output/encodings.pkl\")\n",
    "\n",
    "# Defining tolrance and bounding boxes for faces\n",
    "TOLERANCE = 0.4\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"hog\" # cnn\n",
    "\n",
    "encodings_location = DEFAULT_ENCODINGS_PATH\n",
    "\n",
    "while True:  \n",
    "    with encodings_location.open(mode=\"rb\") as f:\n",
    "        loaded_encodings = pickle.load(f)\n",
    "\n",
    "    frame_req = requests.get(url)\n",
    "    frame_arr = np.array(bytearray(frame_req.content), dtype=np.uint8)\n",
    "    frame = cv.imdecode(frame_arr, -1)\n",
    "    frame = imutils.resize(frame, width=640, height=480)\n",
    "    input_face_locations = face_recognition.face_locations(\n",
    "        frame, model=MODEL\n",
    "    )\n",
    "    input_face_encodings = face_recognition.face_encodings(\n",
    "        frame, input_face_locations\n",
    "    )\n",
    "\n",
    "    for bounding_box, unknown_encoding in zip(\n",
    "        input_face_locations, input_face_encodings\n",
    "    ):\n",
    "\n",
    "        boolean_matches = face_recognition.compare_faces(\n",
    "            loaded_encodings[\"encodings\"], unknown_encoding, TOLERANCE\n",
    "        )\n",
    "\n",
    "        votes = Counter(\n",
    "            name\n",
    "            for match, name in zip(boolean_matches, loaded_encodings[\"names\"])\n",
    "            if match\n",
    "        )\n",
    "        \n",
    "        # Define and execute bounding box for match   \n",
    "        top_left = (bounding_box[3], bounding_box[0])\n",
    "        bottom_right = (bounding_box[1], bounding_box[2])\n",
    "        color = [255, 0, 0]\n",
    "        cv.rectangle(frame, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "        \n",
    "        # Insert name of match in box\n",
    "        if votes:\n",
    "            name = votes.most_common(1)[0][0]\n",
    "            top_left = (bounding_box[3], bounding_box[2])\n",
    "            bottom_right = (bounding_box[1], bounding_box[2]+22)\n",
    "            cv.rectangle(frame, top_left, bottom_right, color, cv.FILLED)\n",
    "            cv.putText(frame, name, (bounding_box[3]+10, bounding_box[2]+15),\n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "          \n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "            top_left = (bounding_box[3], bounding_box[2])\n",
    "            bottom_right = (bounding_box[1], bounding_box[2]+22)\n",
    "            cv.rectangle(frame, top_left, bottom_right, color, cv.FILLED)\n",
    "            cv.putText(frame, name, (bounding_box[3]+10, bounding_box[2]+15),\n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "\n",
    "        cv.imshow(\"Android_cam\", frame)\n",
    "        if cv.waitKey(1) == ord('q') or ConnectionRefusedError:\n",
    "            break\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a82fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950659b",
   "metadata": {},
   "source": [
    "Face-recognition from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d545e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter video file name and its directory : ../bank_face_videos/Madonna on the Arsenio Hall Show_clip.mp4\n",
      "Enter output file name and its directory : ../bank_face_videos/Madonna on the Arsenio Hall Show_IDclip2.mp4\n",
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "# Defining the path for encodings from training image files\n",
    "DEFAULT_ENCODINGS_PATH = Path(\"output/encodings.pkl\")\n",
    "\n",
    "# Defining bounding boxes for faces\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"hog\" # cnn\n",
    "\n",
    "image_location = input('Enter video file name and its directory : ')\n",
    "video = cv.VideoCapture(image_location)\n",
    "width = video.get(cv.CAP_PROP_FRAME_WIDTH)   # 3\n",
    "height = video.get(cv.CAP_PROP_FRAME_HEIGHT)  # 4\n",
    "\n",
    "encodings_location = DEFAULT_ENCODINGS_PATH\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "codec = cv.VideoWriter_fourcc(*\"mp4v\")\n",
    "destination = input(\"Enter output file name and its directory : \")\n",
    "out = cv.VideoWriter(destination, codec, 20.0, (int(width), int(height)))\n",
    "\n",
    "with encodings_location.open(mode=\"rb\") as f:\n",
    "    loaded_encodings = pickle.load(f)\n",
    "    \n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    else:            \n",
    "        input_face_locations = face_recognition.face_locations(\n",
    "            frame, model=MODEL\n",
    "        )\n",
    "        input_face_encodings = face_recognition.face_encodings(\n",
    "            frame, input_face_locations\n",
    "        )\n",
    "\n",
    "        for bounding_box, unknown_encoding in zip(\n",
    "            input_face_locations, input_face_encodings\n",
    "        ):\n",
    "            \n",
    "            boolean_matches = face_recognition.compare_faces(\n",
    "                loaded_encodings[\"encodings\"], unknown_encoding\n",
    "            )\n",
    "\n",
    "            votes = Counter(\n",
    "                name\n",
    "                for match, name in zip(boolean_matches, loaded_encodings[\"names\"])\n",
    "                if match\n",
    "            )\n",
    "            \n",
    "            # Define and execute bounding box for match   \n",
    "            top_left = (bounding_box[3], bounding_box[0])\n",
    "            bottom_right = (bounding_box[1], bounding_box[2])\n",
    "            color = [255, 0, 0]\n",
    "            cv.rectangle(frame, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "\n",
    "            # Insert name of match in box\n",
    "            if votes:\n",
    "                name = votes.most_common(1)[0][0]\n",
    "                top_left = (bounding_box[3], bounding_box[2])\n",
    "                bottom_right = (bounding_box[1], bounding_box[2]+22)\n",
    "                cv.rectangle(frame, top_left, bottom_right, color, cv.FILLED)\n",
    "                cv.putText(frame, name, (bounding_box[3]+10, bounding_box[2]+15),\n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "                top_left = (bounding_box[3], bounding_box[2])\n",
    "                bottom_right = (bounding_box[1], bounding_box[2]+22)\n",
    "                cv.rectangle(frame, top_left, bottom_right, color, cv.FILLED)\n",
    "                cv.putText(frame, name, (bounding_box[3]+10, bounding_box[2]+15),\n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), FONT_THICKNESS)\n",
    "                \n",
    "            out.write(frame)\n",
    "#             cv.imshow('frame', frame)\n",
    "#             if cv.waitKey(1) == ord('q'):\n",
    "#                 break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39f9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c078290",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd5b045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280.0, 720.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = cv.VideoCapture(image_location)\n",
    "width = video.get(cv.CAP_PROP_FRAME_WIDTH)   # 3\n",
    "height = video.get(cv.CAP_PROP_FRAME_HEIGHT)  # 4\n",
    "\n",
    "(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec9f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
